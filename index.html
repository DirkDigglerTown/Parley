<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Parley Protocol — Multi-Agent LLM Debates on Solana Vibes</title>
  <meta name="description" content="A sleek, futuristic demo where multiple local LLMs debate deep questions in your browser via WebGPU (WebLLM)." />
  <link rel="preconnect" href="https://esm.run" />
  <style>
    :root{
      --bg:#05070c; --fg:#e6f1ff; --muted:#9bb0c8; --glass:rgba(255,255,255,.06);
      --accent:#00e5ff; --accent2:#7c4dff; --good:#00e27b; --warn:#ffd166; --bad:#ff5c8a;
    }
    *{box-sizing:border-box;margin:0;padding:0}
    html,body{height:100%;width:100%}
    body{
      font-family:ui-sans-serif,system-ui,Segoe UI,Roboto,Inter,Arial;
      background-color:var(--bg);
      color:var(--fg);
      overflow-x:hidden;
    }
    header{
      position:sticky;top:0;z-index:10;backdrop-filter:saturate(140%) blur(10px);
      background:linear-gradient(180deg, rgba(10,14,20,.9), rgba(10,14,20,.6));
      border-bottom:1px solid rgba(255,255,255,.06);
      padding:14px 24px;display:flex;align-items:center;justify-content:space-between
    }
    .logo{width:36px;height:36px;border-radius:10px;background:conic-gradient(from 120deg,var(--accent),var(--accent2),var(--accent));box-shadow:0 0 30px rgba(0,229,255,.4),inset 0 0 24px rgba(124,77,255,.25)}
    .brand{display:flex;align-items:center;gap:12px}
    .brand h1{font-size:18px;font-weight:700}
    main{width:min(1200px,92vw);margin:0 auto;padding:24px 0 72px;display:grid;gap:24px}
    .hero{position:relative;overflow:hidden;min-height:60vh;border-radius:16px}
    .hero video,.hero img{width:100%;height:100%;object-fit:cover;display:block;pointer-events:none}
    .hero-overlay{position:absolute;inset:0;background:linear-gradient(180deg,rgba(0,0,0,.55),rgba(0,0,0,.2));z-index:1;display:flex;flex-direction:column;justify-content:center;align-items:center;text-align:center;padding:20px}
    .hero-overlay h2{font-size:clamp(28px,4vw,52px);margin-bottom:8px}
    .hero-overlay p{color:var(--muted);max-width:600px}
    .glass{background:var(--glass);border:1px solid rgba(255,255,255,.08);border-radius:18px;padding:16px;box-shadow:0 10px 30px rgba(0,0,0,.35)}
    textarea,select,input,button{width:100%;padding:12px;border-radius:12px;border:1px solid rgba(255,255,255,.12);background:rgba(10,14,22,.65);color:var(--fg)}
    button{cursor:pointer;background:linear-gradient(90deg,var(--accent),var(--accent2));font-weight:700;border:none}
    .agents{display:grid;grid-template-columns:repeat(auto-fit,minmax(240px,1fr));gap:12px}
    .agent{background:rgba(255,255,255,.04);padding:12px;border-radius:14px;border:1px solid rgba(255,255,255,.1)}
    .chat-wrap{position:relative;overflow:hidden;border-radius:16px}
    .chat-bg video,.chat-bg img{width:100%;height:100%;object-fit:cover;filter:blur(1px) brightness(.8);pointer-events:none}
    .chat{position:relative;z-index:1;max-height:52vh;overflow:auto;padding:16px;display:grid;gap:10px;background:linear-gradient(180deg, rgba(3,6,12,.75), rgba(3,6,12,.55))}
    .bubble{padding:12px 14px;border-radius:12px;background:rgba(6,10,16,.6);border:1px solid rgba(255,255,255,.1)}
    .agentA{border-left:3px solid var(--accent)}
    .agentB{border-left:3px solid var(--good)}
    .agentC{border-left:3px solid var(--bad)}
    .wgpu-warning{display:none; background:rgba(255,92,138,0.15); border:1px solid var(--bad); color:var(--bad); padding:10px; border-radius:8px; font-size:14px; margin-bottom:16px;}
    .wgpu-warning a{color:var(--bad); text-decoration:underline;}
  </style>
</head>
<body>
<header>
  <div class="brand"><div class="logo"></div><h1>Parley Protocol</h1></div>
  <small>Powered by <a href="https://webllm.mlc.ai/" target="_blank" style="color:var(--accent)">WebLLM</a></small>
</header>
<main>
  <div id="wgpuBanner" class="wgpu-warning">
    ⚠️ Your browser does not support WebGPU. Parley Protocol requires WebGPU to run AI models locally.
    <a href="https://developer.chrome.com/docs/web-platform/webgpu/#enable-webgpu" target="_blank">Learn how to enable it</a>.
  </div>
  <section class="hero">
    <video src="Intro sting.mp4" poster="Solana-coded UI background.png" autoplay muted playsinline loop></video>
    <div class="hero-overlay">
      <h2>Watch AIs debate the world’s hardest problems</h2>
      <p>Pose a deep, global question. Then watch 2–3 expert personas debate toward a joint plan — all in your browser, no servers.</p>
    </div>
  </section>
  <section class="glass">
    <label>Big Question</label>
    <textarea id="question" placeholder="e.g., How do we reduce the risk of great-power conflict while safeguarding smaller nations' sovereignty?"></textarea>
    <label>Model</label>
    <select id="model">
      <option value="Llama-3.1-8B-Instruct-q4f32_1-MLC">Llama-3.1-8B-Instruct</option>
      <option value="Qwen2-1.5B-Instruct-q4f32_1-MLC">Qwen2-1.5B-Instruct</option>
      <option value="Phi-3-mini-4k-instruct-q4f32_1-MLC">Phi-3-Mini-4k-Instruct</option>
    </select>
    <div class="glass" style="margin-top:12px"><img src="Agent archetypes panel.png" alt="AI agent archetypes" style="width:100%;border-radius:12px"></div>
    <div class="agents">
      <div class="agent"><h4>Agent A — Realist Strategist</h4><textarea id="a">You are a Realist Strategist...</textarea></div>
      <div class="agent"><h4>Agent B — Humanitarian Diplomat</h4><textarea id="b">You are a Humanitarian Diplomat...</textarea></div>
      <div class="agent"><h4>Agent C — Data-Driven Technocrat</h4><textarea id="c">You are a Data-Driven Technocrat...</textarea></div>
    </div>
    <label>Turns per agent</label><input id="turns" type="number" value="2">
    <label>Debate Goal</label><input id="goal" type="text" value="Debate constructively and end with a joint plan.">
    <button id="loadBtn">Load Model</button>
    <button id="runBtn" disabled>Run Parley</button>
    <div id="status">Status: idle</div>
  </section>
  <section class="chat-wrap">
    <div class="chat-bg"><video src="Background loop for chat area.mp4" poster="Neon debate chamber.png" autoplay muted playsinline loop></video></div>
    <div class="chat" id="chat"></div>
  </section>
</main>
<script type="module">
  const statusEl=document.getElementById('status');
  const runBtn=document.getElementById('runBtn');
  const loadBtn=document.getElementById('loadBtn');
  const chatEl=document.getElementById('chat');
  const questionEl=document.getElementById('question');
  const turnsEl=document.getElementById('turns');
  const goalEl=document.getElementById('goal');
  const modelEl=document.getElementById('model');
  const aEl=document.getElementById('a');
  const bEl=document.getElementById('b');
  const cEl=document.getElementById('c');
  const wgpuBanner=document.getElementById('wgpuBanner');
  let engine=null;

  // Show warning if no WebGPU
  if(!('gpu' in navigator)){
    wgpuBanner.style.display = 'block';
  }

  function logBubble(role,text){const div=document.createElement('div');div.className=`bubble agent${role}`;div.textContent=text;chatEl.appendChild(div);chatEl.scrollTop=chatEl.scrollHeight;}
  async function loadModel(){
    statusEl.textContent='Importing WebLLM…';
    loadBtn.disabled=true;
    try{
      const webllm=await import('https://esm.run/@mlc-ai/web-llm');
      engine=await webllm.CreateMLCEngine(modelEl.value,{initProgressCallback:p=>{statusEl.textContent=`Loading: ${Math.round((p.progress||0)*100)}% ${p.text||''}`}});
      runBtn.disabled=false;
      statusEl.textContent='Model ready.';
    }catch(e){
      console.error(e);
      statusEl.textContent='Failed to load model. Enable WebGPU in Chrome/Edge 113+.';
      loadBtn.disabled=false;
    }
  }
  async function generate(messages){const chunks=await engine.chat.completions.create({messages,stream:true,temperature:0.9});let reply='';for await(const ch of chunks){reply+=ch.choices?.[0]?.delta?.content||'';}return reply.trim();}
  function buildPrompt(rolePrompt,userQ,goal){return[{role:'system',content:`${rolePrompt}\nGoal: ${goal}`},{role:'user',content:`Question: ${userQ}`}]}
  async function runParley(){
    if(!engine)return alert('Load a model first.');
    chatEl.innerHTML='';
    const q=questionEl.value.trim();
    const turns=parseInt(turnsEl.value)||1;
    const goal=goalEl.value.trim();
    const personas=[];
    if(aEl.value.trim())personas.push(['A',aEl.value.trim()]);
    if(bEl.value.trim())personas.push(['B',bEl.value.trim()]);
    if(cEl.value.trim())personas.push(['C',cEl.value.trim()]);
    let transcript='';
    for(const [tag,prompt]of personas){
      const msg=await generate(buildPrompt(prompt,q,goal));
      transcript+=`\n\n[${tag}] ${msg}`;
      logBubble(tag,msg);
    }
    for(let t=1;t<turns;t++){
      for(const [tag,prompt]of personas){
        const msg=await generate([{role:'system',content:`${prompt}\nGoal:${goal}`},{role:'user',content:`Transcript so far:\n${transcript}\nWrite your next turn.`}]);
        transcript+=`\n\n[${tag}] ${msg}`;
        logBubble(tag,msg);
      }
    }
    const mod=await generate([{role:'system',content:'You are the Moderator.'},{role:'user',content:`Debate transcript:\n${transcript}\nSummarize into a joint plan.`}]);
    logBubble('Moderator',mod);
  }
  loadBtn.addEventListener('click',loadModel);
  runBtn.addEventListener('click',runParley);
</script>
</body>
</html>
